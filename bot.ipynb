{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a6f45282c7945b39d4157ebfa67c2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e83657a791f47b9a7f594f94566133a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb44ff4d10134694aa41d69b323685b7",
              "IPY_MODEL_cdf03b96ecee4884b4ebb05359038c0b"
            ]
          }
        },
        "2e83657a791f47b9a7f594f94566133a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb44ff4d10134694aa41d69b323685b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01c3aa762141404e8ac780e39544410c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8aea194b53a040ffb0b9679802b86ce0"
          }
        },
        "cdf03b96ecee4884b4ebb05359038c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_23991b1a5a32406f8047ce8563259458",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:19&lt;00:00, 28.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f92843c97344f008569b2054d2bca95"
          }
        },
        "01c3aa762141404e8ac780e39544410c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8aea194b53a040ffb0b9679802b86ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23991b1a5a32406f8047ce8563259458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f92843c97344f008569b2054d2bca95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o12OPkVff2He",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "976e0ec5-c812-47da-a918-91817e678f11"
      },
      "source": [
        "!pip install pyTelegramBotAPI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyTelegramBotAPI\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/1d/40c1fde174731bd58f014721a37c28d35210aa39c42c3e8b1659374a9bec/pyTelegramBotAPI-3.7.1.tar.gz (70kB)\n",
            "\r\u001b[K     |████▋                           | 10kB 26.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pyTelegramBotAPI) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyTelegramBotAPI) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (1.24.3)\n",
            "Building wheels for collected packages: pyTelegramBotAPI\n",
            "  Building wheel for pyTelegramBotAPI (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTelegramBotAPI: filename=pyTelegramBotAPI-3.7.1-cp36-none-any.whl size=50883 sha256=8d4676dfd8b3ba515d9dfc10bc37967fb6552d143fce7693d872a81c62d6499c\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/b2/2c/eac6af3343b21f907123ce013d20ad5ad70c2c3731072d98bf\n",
            "Successfully built pyTelegramBotAPI\n",
            "Installing collected packages: pyTelegramBotAPI\n",
            "Successfully installed pyTelegramBotAPI-3.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qmY32qbeN5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import telebot\n",
        "from telebot import types\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import torch.optim.lr_scheduler as sched\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXKOXcFhhBDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "8a6f45282c7945b39d4157ebfa67c2c7",
            "2e83657a791f47b9a7f594f94566133a",
            "fb44ff4d10134694aa41d69b323685b7",
            "cdf03b96ecee4884b4ebb05359038c0b",
            "01c3aa762141404e8ac780e39544410c",
            "8aea194b53a040ffb0b9679802b86ce0",
            "23991b1a5a32406f8047ce8563259458",
            "6f92843c97344f008569b2054d2bca95"
          ]
        },
        "outputId": "7a8953ed-adb8-42ed-c365-1ac63de7f14d"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def image_loader(image_name):\n",
        "    image = Image.open(image_name)\n",
        "    image = loader(image).unsqueeze(0)\n",
        "    return image.to(device, torch.float)\n",
        "\n",
        "\n",
        "cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
        "cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
        "\n",
        "\n",
        "class Normalization(nn.Module):\n",
        "        def __init__(self, mean, std):\n",
        "            super(Normalization, self).__init__()\n",
        "            self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
        "            self.std = torch.tensor(std).view(-1, 1, 1)\n",
        "\n",
        "        def forward(self, img):\n",
        "            return (img - self.mean) / self.std\n",
        "\n",
        "\n",
        "imsize = 478\n",
        "loader = transforms.Compose([\n",
        "    transforms.Resize(imsize),  # нормируем размер изображения\n",
        "    transforms.CenterCrop(imsize),\n",
        "    transforms.ToTensor()])\n",
        "unloader = transforms.ToPILImage() # тензор в кратинку\n",
        "plt.ion()\n",
        "\n",
        "\n",
        "def gram_matrix(input_img):\n",
        "    batch_size, f_map_num, h, w = input_img.size()\n",
        "    features = input_img.view(batch_size * f_map_num, h * w)\n",
        "    g = torch.mm(features, features.t())\n",
        "    return g.div(batch_size * h * w * f_map_num)\n",
        "\n",
        "\n",
        "class ContentLoss(nn.Module):\n",
        "    def __init__(self, target, ):\n",
        "        super(ContentLoss, self).__init__()\n",
        "        self.target = target.detach()\n",
        "        self.loss = F.mse_loss(self.target, self.target)\n",
        "\n",
        "    def forward(self, input_img):\n",
        "        self.loss = F.mse_loss(input_img, self.target)\n",
        "        return input_img\n",
        "\n",
        "\n",
        "class StyleLoss(nn.Module):\n",
        "    def __init__(self, target_feature):\n",
        "        super(StyleLoss, self).__init__()\n",
        "        self.target = gram_matrix(target_feature).detach()\n",
        "        self.loss = F.mse_loss(self.target, self.target)\n",
        "\n",
        "    def forward(self, input_img):\n",
        "        g = gram_matrix(input_img)\n",
        "        self.loss = F.mse_loss(g, self.target)\n",
        "        return input_img\n",
        "\n",
        "\n",
        "cnn = models.vgg19(pretrained=True).features.to(device).eval()\n",
        "content_layers_default = ['conv_4']\n",
        "style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
        "\n",
        "\n",
        "def get_input_optimizer(input_img):\n",
        "    optimizer = optim.LBFGS([input_img.requires_grad_()])\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n",
        "                               style_img, content_img,\n",
        "                               content_layers=content_layers_default,\n",
        "                               style_layers=style_layers_default):\n",
        "    cnn = copy.deepcopy(cnn)\n",
        "    normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
        "    content_losses = []\n",
        "    style_losses = []\n",
        "    model = nn.Sequential(normalization)\n",
        "\n",
        "    i = 0\n",
        "    for layer in cnn.children():\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            i += 1\n",
        "            name = 'conv_{}'.format(i)\n",
        "        elif isinstance(layer, nn.ReLU):\n",
        "            name = 'relu_{}'.format(i)\n",
        "            layer = nn.ReLU(inplace=False)\n",
        "        elif isinstance(layer, nn.MaxPool2d):\n",
        "            name = 'pool_{}'.format(i)\n",
        "        elif isinstance(layer, nn.BatchNorm2d):\n",
        "            name = 'bn_{}'.format(i)\n",
        "        else:\n",
        "            raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
        "\n",
        "        model.add_module(name, layer)\n",
        "\n",
        "        if name in content_layers:\n",
        "            # add content loss:\n",
        "            target = model(content_img).detach()\n",
        "            content_loss = ContentLoss(target)\n",
        "            model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
        "            content_losses.append(content_loss)\n",
        "\n",
        "        if name in style_layers:\n",
        "            target_feature = model(style_img).detach()\n",
        "            style_loss = StyleLoss(target_feature)\n",
        "            model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
        "            style_losses.append(style_loss)\n",
        "    for i in range(len(model) - 1, -1, -1):\n",
        "        if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
        "            break\n",
        "\n",
        "    model = model[:(i + 1)]\n",
        "\n",
        "    return model, style_losses, content_losses\n",
        "\n",
        "\n",
        "def run_style_transfer(cnn, normalization_mean, normalization_std,\n",
        "                       content_img, style_img, input_img, chat_id, num_steps=400,\n",
        "                       style_weight=100000, content_weight=1):\n",
        "    model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
        "                                                                     normalization_mean, normalization_std,\n",
        "                                                                     style_img, content_img)\n",
        "\n",
        "    optimizer = get_input_optimizer(input_img)\n",
        "    sheduler = sched.StepLR(optimizer=optimizer, step_size=100, gamma=0.1)\n",
        "\n",
        "    run = [0]\n",
        "    while run[0] <= num_steps:\n",
        "\n",
        "        def closure():\n",
        "            input_img.data.clamp_(0, 1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            model(input_img)\n",
        "\n",
        "            style_score = 0\n",
        "            content_score = 0\n",
        "\n",
        "            for sl in style_losses:\n",
        "                style_score += sl.loss\n",
        "            for cl in content_losses:\n",
        "                content_score += cl.loss\n",
        "            # взвешивание ощибки\n",
        "            style_score *= style_weight\n",
        "            content_score *= content_weight\n",
        "\n",
        "            loss = style_score + content_score\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            run[0] += 1\n",
        "\n",
        "            if run[0] % 100 == 0:\n",
        "                bot.send_message(chat_id, str(int(run[0]/400 * 100)) + ' %')\n",
        "\n",
        "            return style_score + content_score\n",
        "\n",
        "        optimizer.step(closure)\n",
        "\n",
        "        sheduler.step()\n",
        "\n",
        "    # a last correction...\n",
        "    input_img.data.clamp_(0, 1)\n",
        "\n",
        "    return input_img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a6f45282c7945b39d4157ebfa67c2c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=574673361.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7q1ogALn-_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43150ea-2a51-40ad-db3f-22e0d0826ac1"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODz19ERK7wz3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6c1fd0-cc74-4743-e40a-9aab120494a5"
      },
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2271, done.\u001b[K\n",
            "remote: Total 2271 (delta 0), reused 0 (delta 0), pack-reused 2271\u001b[K\n",
            "Receiving objects: 100% (2271/2271), 8.06 MiB | 5.61 MiB/s, done.\n",
            "Resolving deltas: 100% (1462/1462), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JmXdFqI0vD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73005899-7545-4ae4-f1ff-9450bebc8d1f"
      },
      "source": [
        "!bash ./scripts/download_cyclegan_model.sh style_cezanne\n",
        "!bash ./scripts/download_cyclegan_model.sh style_monet\n",
        "!bash ./scripts/download_cyclegan_model.sh style_vangogh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: available models are apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower\n",
            "Specified [style_cezanne]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2020-07-02 19:01:01--  http://efrosgans.eecs.berkeley.edu/cyclegan/pretrained_models/style_cezanne.pth\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.189.73|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45575747 (43M)\n",
            "Saving to: ‘./checkpoints/style_cezanne_pretrained/latest_net_G.pth’\n",
            "\n",
            "./checkpoints/style 100%[===================>]  43.46M  14.9MB/s    in 2.9s    \n",
            "\n",
            "2020-07-02 19:01:04 (14.9 MB/s) - ‘./checkpoints/style_cezanne_pretrained/latest_net_G.pth’ saved [45575747/45575747]\n",
            "\n",
            "Note: available models are apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower\n",
            "Specified [style_monet]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2020-07-02 19:01:06--  http://efrosgans.eecs.berkeley.edu/cyclegan/pretrained_models/style_monet.pth\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.189.73|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45575747 (43M)\n",
            "Saving to: ‘./checkpoints/style_monet_pretrained/latest_net_G.pth’\n",
            "\n",
            "./checkpoints/style 100%[===================>]  43.46M  14.8MB/s    in 2.9s    \n",
            "\n",
            "2020-07-02 19:01:09 (14.8 MB/s) - ‘./checkpoints/style_monet_pretrained/latest_net_G.pth’ saved [45575747/45575747]\n",
            "\n",
            "Note: available models are apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower\n",
            "Specified [style_vangogh]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2020-07-02 19:01:10--  http://efrosgans.eecs.berkeley.edu/cyclegan/pretrained_models/style_vangogh.pth\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.189.73|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45575747 (43M)\n",
            "Saving to: ‘./checkpoints/style_vangogh_pretrained/latest_net_G.pth’\n",
            "\n",
            "./checkpoints/style 100%[===================>]  43.46M  14.8MB/s    in 2.9s    \n",
            "\n",
            "2020-07-02 19:01:14 (14.8 MB/s) - ‘./checkpoints/style_vangogh_pretrained/latest_net_G.pth’ saved [45575747/45575747]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMD1zj7aasyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "96d9839c-14d5-4365-ed36-e65f63de4309"
      },
      "source": [
        "!pip install dominate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/e6/794a119963b7cfe4bd41177c8f9d4195fe901652f04189fbd2edf513c7b2/dominate-2.5.1-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHpfJlRlaXmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155679ff-b8d0-4797-877d-5ff6c4ad1928"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints\tdocs\t\t models\t\trequirements.txt  util\n",
            "CycleGAN.ipynb\tenvironment.yml  options\tscripts\n",
            "data\t\timgs\t\t pix2pix.ipynb\ttest.py\n",
            "datasets\tLICENSE\t\t README.md\ttrain.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xlMvhm0MbV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir content\n",
        "!mkdir style\n",
        "!mkdir result\n",
        "!mkdir cezanne\n",
        "!mkdir monet\n",
        "!mkdir vangogh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnMeylrxeHu2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b097f4b3-5990-44e2-b78e-a979efa8199e"
      },
      "source": [
        "id_to_stage = {}\n",
        "\n",
        "token = '1266472120:AAFOzabwzE_i7pesFN9JykneIom5ywpPY-8'\n",
        "bot = telebot.TeleBot(token) # Токен API к Telegram\n",
        "\n",
        "\n",
        "@bot.message_handler(commands=['start'])\n",
        "def start_message(message):\n",
        "    id_to_stage[message.chat.id] = 'start'\n",
        "    bot.send_message(message.chat.id, 'Привет, я буду стилизовать фотографии. \\\n",
        "Если ты здесь впервые или тебе нужна помощь, нажми на /help.')\n",
        "    markup = types.InlineKeyboardMarkup()\n",
        "    button_cezanne = types.InlineKeyboardButton(text='Cezanne style', \n",
        "                                                callback_data='cezanne')\n",
        "    button_monet = types.InlineKeyboardButton(text='Monet style', \n",
        "                                              callback_data='monet')\n",
        "    button_vangogh = types.InlineKeyboardButton(text='van Gogh style', \n",
        "                                                callback_data='vangogh')\n",
        "    button_custom = types.InlineKeyboardButton(text='Custom style', \n",
        "                                               callback_data='custom')\n",
        "    markup.add(button_cezanne, button_monet, button_vangogh, button_custom)\n",
        "    bot.send_message(message.chat.id, text='Выбери режим: \\nCezanne - стилизация \\\n",
        "под картины Поля Сезанна\\nMonet - стилизация под картины Клода Моне\\nvan Gogh -\\\n",
        "стилизация под картины Винсента ван Гога\\nCustom - \\\n",
        "стилизация под выбранную тобой фотографию',\n",
        "    reply_markup=markup)\n",
        "\n",
        "\n",
        "@bot.message_handler(commands=['help'])\n",
        "def start_message(message):\n",
        "    chat_id = message.chat.id\n",
        "    if (chat_id not in id_to_stage):\n",
        "        id_to_stage[chat_id] = 'start'\n",
        "    if id_to_stage[chat_id] == 'start':  \n",
        "        bot.send_message(message.chat.id, text='Выбери режим стилизации /mode')\n",
        "    elif id_to_stage[chat_id] in ['content', 'cezanne', 'monet', 'vangogh']:\n",
        "        bot.send_message(chat_id, 'Отправь фотографию, которую я буду стилизовать!')\n",
        "    elif id_to_stage[chat_id] == 'style':\n",
        "        bot.send_message(chat_id, 'Отправь фотографию, с которой я буду брать стиль')\n",
        "\n",
        "\n",
        "@bot.message_handler(commands=['mode'])\n",
        "def start_message(message):\n",
        "    chat_id = message.chat.id\n",
        "    id_to_stage[chat_id] = 'start'\n",
        "    markup = types.InlineKeyboardMarkup()\n",
        "    button_cezanne = types.InlineKeyboardButton(text='Cezanne style', \n",
        "                                                callback_data='cezanne')\n",
        "    button_monet = types.InlineKeyboardButton(text='Monet style', \n",
        "                                              callback_data='monet')\n",
        "    button_vangogh = types.InlineKeyboardButton(text='van Gogh style', \n",
        "                                                callback_data='vangogh')\n",
        "    button_custom = types.InlineKeyboardButton(text='Custom style', \n",
        "                                               callback_data='custom')\n",
        "    markup.add(button_cezanne, button_monet, button_vangogh, button_custom)\n",
        "    \n",
        "    bot.send_message(chat_id, text='Выбери стиль', \n",
        "    reply_markup=markup)\n",
        "\n",
        "\n",
        "@bot.message_handler(commands=['end'])\n",
        "def start_message(message):\n",
        "    chat_id = message.chat.id\n",
        "    id_to_stage[chat_id] = 'end'\n",
        "    bot.send_message(chat_id, 'Работа завершена')\n",
        "\n",
        "\n",
        "@bot.callback_query_handler(func=lambda call: True)\n",
        "def query_handler(call):\n",
        "    if call.data == 'cezanne':\n",
        "        bot.answer_callback_query(callback_query_id=call.id, text='Ты выбрал \\\n",
        "стиль картин Поля Сезанна')\n",
        "        id_to_stage[call.from_user.id] = 'cezanne'\n",
        "        bot.send_message(call.from_user.id, 'Выбран стиль Поля Сезанна. \\\n",
        "Отправь фотографию, которую я буду стилизовать!')\n",
        "    elif call.data == 'monet':\n",
        "        bot.answer_callback_query(callback_query_id=call.id, text='Ты выбрал \\\n",
        "стиль картин Клода Моне')\n",
        "        id_to_stage[call.from_user.id] = 'monet'\n",
        "        bot.send_message(call.from_user.id, 'Выбран стиль Клода Моне. \\\n",
        "Отправь фотографию, которую я буду стилизовать!')\n",
        "    elif call.data == 'vangogh':\n",
        "        bot.answer_callback_query(callback_query_id=call.id, text='Ты выбрал \\\n",
        "стиль картин Винсента ван Гога')\n",
        "        id_to_stage[call.from_user.id] = 'vangogh'\n",
        "        bot.send_message(call.from_user.id, 'Выбран стиль Винсента ван Гога. \\\n",
        "Отправь фотографию, которую я буду стилизовать!')\n",
        "    elif call.data == 'custom':\n",
        "        bot.answer_callback_query(callback_query_id=call.id, text='Ты выбрал \\\n",
        "собственный стиль')\n",
        "        id_to_stage[call.from_user.id] = 'content'\n",
        "        bot.send_message(call.from_user.id, 'Отправь фотографию, которую я \\\n",
        "буду стилизовать!')\n",
        "\n",
        "\n",
        "@bot.message_handler(content_types=[\"text\", \"sticker\", \"pinned_message\", \"audio\"])\n",
        "def echo_msg(message):\n",
        "    chat_id = message.chat.id\n",
        "    if (chat_id not in id_to_stage):\n",
        "        id_to_stage[message.chat.id] = 'start'\n",
        "    if message.content_type == 'text':\n",
        "        if id_to_stage[chat_id] in ['content', 'cezanne', 'monet', 'vangogh']:\n",
        "            bot.send_message(chat_id, 'Отправь фотографию, которую я буду стилизовать!')\n",
        "        elif id_to_stage[chat_id] == 'style':\n",
        "            bot.send_message(chat_id, 'Отправь фотографию, с которой я буду брать стиль!')\n",
        "        else:\n",
        "            bot.send_message(chat_id, 'Для начала выбери режим стилизации - /mode')\n",
        "\n",
        "\n",
        "@bot.message_handler(content_types=['photo'])\n",
        "def handle_docs_photo(message):\n",
        "    chat_id = message.chat.id\n",
        "    if chat_id not in id_to_stage:\n",
        "        id_to_stage[chat_id] = 'start'\n",
        "    if id_to_stage[chat_id] == 'start':\n",
        "        bot.send_message(chat_id, 'Перед тем, как отправлять фотографию \\\n",
        "нужно выбрать режим стилижации - /mode')\n",
        "    try:\n",
        "        file_info = bot.get_file(message.photo[len(message.photo) - 1].file_id)\n",
        "        downloaded_file = bot.download_file(file_info.file_path)\n",
        "        if id_to_stage[chat_id] in ['content', 'cezanne', 'monet', 'vangogh', 'style']:\n",
        "            src = id_to_stage[chat_id] + '/' + str(chat_id) + '.jpg'\n",
        "        else:\n",
        "            src = file_info.file_path\n",
        "        with open(src, 'wb') as new_file:\n",
        "            new_file.write(downloaded_file)\n",
        "        if id_to_stage[chat_id] == 'content':\n",
        "            id_to_stage[chat_id] = 'style'\n",
        "            bot.reply_to(message, \"Фото контента добавлено. Теперь отправь фотографию, с которой я буду\"\n",
        "                                  \" переносить стиль.\")\n",
        "        elif id_to_stage[chat_id] == 'cezanne':\n",
        "            id_to_stage[chat_id] = 'start'\n",
        "            bot.reply_to(message, \"Фото добавлено. Начинаю обработку...\")\n",
        "            !python test.py --dataroot cezanne --name style_cezanne_pretrained --model test --no_dropout\n",
        "            bot.send_photo(chat_id, open('./results/style_cezanne_pretrained/test_latest/images/' + str(chat_id) + '_fake.png', 'rb'))\n",
        "        elif id_to_stage[chat_id] == 'monet':\n",
        "            id_to_stage[chat_id] = 'start'\n",
        "            bot.reply_to(message, \"Фото добавлено. Начинаю обработку...\")\n",
        "            !python test.py --dataroot monet --name style_monet_pretrained --model test --no_dropout\n",
        "            bot.send_photo(chat_id, open('./results/style_monet_pretrained/test_latest/images/' + str(chat_id) + '_fake.png', 'rb'))\n",
        "        elif id_to_stage[chat_id] == 'vangogh':\n",
        "            id_to_stage[chat_id] = 'start'\n",
        "            bot.reply_to(message, \"Фото добавлено. Начинаю обработку...\")\n",
        "            !python test.py --dataroot vangogh --name style_vangogh_pretrained --model test --no_dropout\n",
        "            bot.send_photo(chat_id, open('results/style_vangogh_pretrained/test_latest/images/' + str(chat_id) + '_fake.png', 'rb'))\n",
        "        elif id_to_stage[chat_id] == 'style':\n",
        "            id_to_stage[chat_id] = 'start'\n",
        "            bot.reply_to(message, \"Фото стиля добавлено. Начинаю обработку...\")\n",
        "            content_img = image_loader('content/' + str(chat_id) + '.jpg')\n",
        "            style_img = image_loader('style/' + str(chat_id) + '.jpg')\n",
        "            input_img = torch.randn(content_img.data.size(), device=device)\n",
        "            output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std, content_img,\n",
        "                                                 style_img, input_img, chat_id)\n",
        "            \n",
        "            image = output.cpu().clone()   \n",
        "            image = image.squeeze(0)     \n",
        "            image = unloader(image)\n",
        "            image.save('result/' + str(chat_id) + '.jpg')\n",
        "            bot.send_photo(chat_id, open('result/' + str(chat_id) + '.jpg', 'rb'))\n",
        "\n",
        "    except Exception as e:\n",
        "        bot.reply_to(message, e)\n",
        "\n",
        "\n",
        "bot.polling(none_stop=True, interval=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: cezanne                       \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: style_cezanne_pretrained      \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/style_cezanne_pretrained/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/style_cezanne_pretrained/test_latest\n",
            "processing (0000)-th image... ['cezanne/473283432.jpg']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: monet                         \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: style_monet_pretrained        \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/style_monet_pretrained/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/style_monet_pretrained/test_latest\n",
            "processing (0000)-th image... ['monet/473283432.jpg']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: vangogh                       \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: style_vangogh_pretrained      \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/style_vangogh_pretrained/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/style_vangogh_pretrained/test_latest\n",
            "processing (0000)-th image... ['vangogh/473283432.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0S5QoH389-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nXSKhoG9MfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}